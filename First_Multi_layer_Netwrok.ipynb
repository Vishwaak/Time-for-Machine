{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First-Multi-layer Netwrok.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishwaak/Time-for-Machine/blob/master/First_Multi_layer_Netwrok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAX9uXVdM62G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import helper\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGBP5wNKPYl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcHttBGrQe9Y",
        "colab_type": "code",
        "outputId": "625a95d0-0716-4c17-9db6-13e3547a8891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images , labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K1OguHOb9Pw",
        "colab_type": "code",
        "outputId": "0d587888-b95f-4f24-d633-4de20e09ab99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze() ,cmap='Greys_r')\n",
        "print(labels[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0DFBDwAdE/QA0LH/D8efxJDT3+TFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 253,
              "height": 250
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q200LGPchi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activation(x):\n",
        "  return 1/(1+torch.exp(-x))\n",
        "\n",
        "inputs = images.view(images.shape[0] , -1)\n",
        "\n",
        "w1 = torch.randn(784,256)\n",
        "b1 = torch.randn(256)\n",
        "\n",
        "w2 = torch.randn(256,10)\n",
        "b2 = torch.randn(10)\n",
        "\n",
        "h= activation(torch.mm(inputs , w1) + b1)\n",
        "out = torch.mm(h,w2) + b2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWj9-xaXef-k",
        "colab_type": "code",
        "outputId": "40f3ecc8-6649-445f-eede-37883ba30334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "\n",
        "def softmax(x):\n",
        "  return (torch.exp(x)/torch.sum(torch.exp(x) , dim=1).view(-1,1))\n",
        "probability = softmax(out)\n",
        "\n",
        "print(probability.shape)\n",
        "print(probability.sum(dim =1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32EKpafgijXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn \n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Hidden layer with sigmoid activation\n",
        "        x = F.sigmoid(self.hidden(x))\n",
        "        # Output layer with softmax activation\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "554TkExkMZsD",
        "colab_type": "code",
        "outputId": "e9167a31-5359-4719-959c-1a601e2c9778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our log-probabilities\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3409, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e--d84tunxmZ",
        "colab_type": "code",
        "outputId": "bd3f5967-3e4c-4b4a-cb83-6f72487b70ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our log-probabilities\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3036, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQJ3naIFlNCb",
        "colab_type": "code",
        "outputId": "a63dcc6b-37ab-426e-b474-3a73389058f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "print('Before backward pass: \\n' , model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n' , model[0].weight.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[ 4.3180e-04,  4.3180e-04,  4.3180e-04,  ...,  4.3180e-04,\n",
            "          4.3180e-04,  4.3180e-04],\n",
            "        [-8.4394e-05, -8.4394e-05, -8.4394e-05,  ..., -8.4394e-05,\n",
            "         -8.4394e-05, -8.4394e-05],\n",
            "        [-1.5423e-04, -1.5423e-04, -1.5423e-04,  ..., -1.5423e-04,\n",
            "         -1.5423e-04, -1.5423e-04],\n",
            "        ...,\n",
            "        [ 7.5457e-04,  7.5457e-04,  7.5457e-04,  ...,  7.5457e-04,\n",
            "          7.5457e-04,  7.5457e-04],\n",
            "        [ 5.0900e-03,  5.0900e-03,  5.0900e-03,  ...,  5.0900e-03,\n",
            "          5.0900e-03,  5.0900e-03],\n",
            "        [ 4.0394e-04,  4.0394e-04,  4.0394e-04,  ...,  4.0394e-04,\n",
            "          4.0394e-04,  4.0394e-04]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik2m-aEENEUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_47Yi6UvRcjz",
        "colab_type": "code",
        "outputId": "dfb489e8-e6c8-4e73-f8e0-76a2ef8be0ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[-0.0018,  0.0082, -0.0162,  ..., -0.0135, -0.0293,  0.0221],\n",
            "        [ 0.0113, -0.0306,  0.0223,  ..., -0.0256, -0.0256,  0.0280],\n",
            "        [ 0.0204, -0.0318,  0.0313,  ...,  0.0233,  0.0017,  0.0230],\n",
            "        ...,\n",
            "        [ 0.0327,  0.0008,  0.0233,  ..., -0.0009, -0.0211, -0.0241],\n",
            "        [-0.0287,  0.0122,  0.0185,  ..., -0.0047, -0.0352, -0.0351],\n",
            "        [ 0.0207, -0.0228,  0.0157,  ..., -0.0147, -0.0033, -0.0309]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[-7.3267e-03, -7.3267e-03, -7.3267e-03,  ..., -7.3267e-03,\n",
            "         -7.3267e-03, -7.3267e-03],\n",
            "        [-4.7552e-05, -4.7552e-05, -4.7552e-05,  ..., -4.7552e-05,\n",
            "         -4.7552e-05, -4.7552e-05],\n",
            "        [ 1.3015e-04,  1.3015e-04,  1.3015e-04,  ...,  1.3015e-04,\n",
            "          1.3015e-04,  1.3015e-04],\n",
            "        ...,\n",
            "        [-3.3157e-04, -3.3157e-04, -3.3157e-04,  ..., -3.3157e-04,\n",
            "         -3.3157e-04, -3.3157e-04],\n",
            "        [ 2.3984e-03,  2.3984e-03,  2.3984e-03,  ...,  2.3984e-03,\n",
            "          2.3984e-03,  2.3984e-03],\n",
            "        [-1.5950e-03, -1.5950e-03, -1.5950e-03,  ..., -1.5950e-03,\n",
            "         -1.5950e-03, -1.5950e-03]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQkFlZXdRf19",
        "colab_type": "code",
        "outputId": "d053e6f1-a738-4331-cce1-fc6505993c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Take an update step and few the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[-0.0018,  0.0083, -0.0161,  ..., -0.0134, -0.0292,  0.0222],\n",
            "        [ 0.0113, -0.0306,  0.0223,  ..., -0.0256, -0.0256,  0.0280],\n",
            "        [ 0.0204, -0.0318,  0.0313,  ...,  0.0233,  0.0017,  0.0230],\n",
            "        ...,\n",
            "        [ 0.0327,  0.0008,  0.0233,  ..., -0.0009, -0.0211, -0.0241],\n",
            "        [-0.0288,  0.0122,  0.0185,  ..., -0.0047, -0.0352, -0.0351],\n",
            "        [ 0.0207, -0.0228,  0.0157,  ..., -0.0147, -0.0033, -0.0309]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZrVu3m2RitX",
        "colab_type": "code",
        "outputId": "1347ba63-6e82-4268-fc52-ccb13c584c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images, labels in trainloader:\n",
        "    images = images.view(images.shape[0], -1)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    output = model.forward(images)\n",
        "    loss = criterion(output , labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "  else:\n",
        "      print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.8609886568492409\n",
            "Training loss: 0.8303229662972981\n",
            "Training loss: 0.5193114361560929\n",
            "Training loss: 0.4259157420348511\n",
            "Training loss: 0.38231278620739734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnRZDEguhxQk",
        "colab_type": "code",
        "outputId": "1aa1ea6a-a2b4-4ee7-cc19-be94a58e1d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "import helper\n",
        "from torch import F\n",
        "images , labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1,784)\n",
        "\n",
        "#Turning off gradient to speed up the process\n",
        "with torch.no_grad():\n",
        "  logits= model.forward(img)\n",
        "  \n",
        "pa = F.softmax(logits , dis= 1)\n",
        "helper.view_classify(img.view(1,28,28) , pe)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-df6f657c30c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'F'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}