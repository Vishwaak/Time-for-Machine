{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Validation and inference.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishwaak/Time-for-Machine/blob/master/Validation_and_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW_K2Fv4jrAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import helper\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the training data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOyhA4vsIDvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRbD7iE6IJ3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TWp7lRBSugR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaM_hoNgIRTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Network model.\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(784 , 256)\n",
        "    self.fc2 = nn.Linear(256 , 128)\n",
        "    self.fc3 = nn.Linear(128 , 64)\n",
        "    self.fc4 = nn.Linear(64 , 10)\n",
        "    \n",
        "  def forward(self ,x):\n",
        "    x = x.view(x.shape[0] , -1)\n",
        "    \n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = F.log_softmax(self.fc4(x) , dim =1)\n",
        "    \n",
        "    return x\n",
        "     \n",
        "    \n",
        "   \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hxw8xFzRJA3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c6ed977-5e07-4740-be22-eba6cf3beac8"
      },
      "source": [
        "model = Classifier()\n",
        "\n",
        "images, labels = next(iter(testloader))\n",
        "# Get the class probabilities\n",
        "ps = torch.exp(model(images))\n",
        "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
        "print(ps.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNr5CJvyUDtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "6d2927e5-05ab-4932-8b58-f59f1c0d188d"
      },
      "source": [
        "top_p, top_class = ps.topk(1, dim=1)\n",
        "# Look at the most likely classes for the first 10 examples\n",
        "print(top_class[:10,:])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4],\n",
            "        [4],\n",
            "        [8],\n",
            "        [8],\n",
            "        [8],\n",
            "        [4],\n",
            "        [4],\n",
            "        [8],\n",
            "        [4],\n",
            "        [4]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_edI-onUxfJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "equals = top_class == labels.view(*top_class.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOJFIrUSxlCG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cddef2ee-32eb-4bc2-f8a7-f379f649a677"
      },
      "source": [
        "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
        "print(f'Accuracy: {accuracy.item()*100}%')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 6.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suu6hZml2RiR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "2e486fcb-65f5-46be-c839-304526d33a26"
      },
      "source": [
        "model = Classifier()\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.003)\n",
        "\n",
        "epochs = 30\n",
        "steps = 0\n",
        "\n",
        "train_losses, test_losses = [] , []\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images , labels in trainloader:\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    log_ps = model(images)\n",
        "    loss = criterion(log_ps , labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "    \n",
        "  else:\n",
        "      test_loss = 0\n",
        "      accuracy = 0\n",
        "      \n",
        "      with torch.no_grad():\n",
        "        for images , labels in testloader:\n",
        "          log_ps = model(images)\n",
        "          test_loss += criterion(log_ps , labels)\n",
        "          \n",
        "          ps = torch.exp(log_ps)\n",
        "          top_p , top_class = ps.topk(1 , dim=1)\n",
        "          equals = top_class == labels.view(*top_class.shape)\n",
        "          accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "    \n",
        "  train_losses.append(running_loss/len(trainloader))\n",
        "  test_losses.append(test_loss/len(testloader))\n",
        "    \n",
        "  print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/30..  Training Loss: 0.513..  Test Loss: 0.455..  Test Accuracy: 0.829\n",
            "Epoch: 2/30..  Training Loss: 0.391..  Test Loss: 0.389..  Test Accuracy: 0.858\n",
            "Epoch: 3/30..  Training Loss: 0.352..  Test Loss: 0.393..  Test Accuracy: 0.861\n",
            "Epoch: 4/30..  Training Loss: 0.332..  Test Loss: 0.381..  Test Accuracy: 0.868\n",
            "Epoch: 5/30..  Training Loss: 0.316..  Test Loss: 0.396..  Test Accuracy: 0.865\n",
            "Epoch: 6/30..  Training Loss: 0.304..  Test Loss: 0.382..  Test Accuracy: 0.866\n",
            "Epoch: 7/30..  Training Loss: 0.291..  Test Loss: 0.386..  Test Accuracy: 0.867\n",
            "Epoch: 8/30..  Training Loss: 0.281..  Test Loss: 0.380..  Test Accuracy: 0.872\n",
            "Epoch: 9/30..  Training Loss: 0.272..  Test Loss: 0.359..  Test Accuracy: 0.875\n",
            "Epoch: 10/30..  Training Loss: 0.270..  Test Loss: 0.368..  Test Accuracy: 0.881\n",
            "Epoch: 11/30..  Training Loss: 0.258..  Test Loss: 0.358..  Test Accuracy: 0.878\n",
            "Epoch: 12/30..  Training Loss: 0.254..  Test Loss: 0.388..  Test Accuracy: 0.867\n",
            "Epoch: 13/30..  Training Loss: 0.244..  Test Loss: 0.391..  Test Accuracy: 0.871\n",
            "Epoch: 14/30..  Training Loss: 0.240..  Test Loss: 0.408..  Test Accuracy: 0.870\n",
            "Epoch: 15/30..  Training Loss: 0.235..  Test Loss: 0.396..  Test Accuracy: 0.874\n",
            "Epoch: 16/30..  Training Loss: 0.233..  Test Loss: 0.379..  Test Accuracy: 0.882\n",
            "Epoch: 17/30..  Training Loss: 0.225..  Test Loss: 0.369..  Test Accuracy: 0.883\n",
            "Epoch: 18/30..  Training Loss: 0.223..  Test Loss: 0.365..  Test Accuracy: 0.884\n",
            "Epoch: 19/30..  Training Loss: 0.216..  Test Loss: 0.402..  Test Accuracy: 0.879\n",
            "Epoch: 20/30..  Training Loss: 0.209..  Test Loss: 0.394..  Test Accuracy: 0.882\n",
            "Epoch: 21/30..  Training Loss: 0.209..  Test Loss: 0.433..  Test Accuracy: 0.877\n",
            "Epoch: 22/30..  Training Loss: 0.205..  Test Loss: 0.397..  Test Accuracy: 0.878\n",
            "Epoch: 23/30..  Training Loss: 0.204..  Test Loss: 0.414..  Test Accuracy: 0.880\n",
            "Epoch: 24/30..  Training Loss: 0.201..  Test Loss: 0.371..  Test Accuracy: 0.886\n",
            "Epoch: 25/30..  Training Loss: 0.196..  Test Loss: 0.420..  Test Accuracy: 0.878\n",
            "Epoch: 26/30..  Training Loss: 0.190..  Test Loss: 0.375..  Test Accuracy: 0.885\n",
            "Epoch: 27/30..  Training Loss: 0.190..  Test Loss: 0.430..  Test Accuracy: 0.877\n",
            "Epoch: 28/30..  Training Loss: 0.184..  Test Loss: 0.389..  Test Accuracy: 0.881\n",
            "Epoch: 29/30..  Training Loss: 0.187..  Test Loss: 0.404..  Test Accuracy: 0.884\n",
            "Epoch: 30/30..  Training Loss: 0.186..  Test Loss: 0.469..  Test Accuracy: 0.882\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}